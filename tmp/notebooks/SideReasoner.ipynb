{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import os\n",
    "\n",
    "## set ENV variables\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\"\n",
    "\n",
    "# os.environ[\"GEMINI_API_KEY\"] = \"\"\n",
    "os.environ[\"TOGETHERAI_API_KEY\"] = \"dc7b6e35a7a0e0a582905d0c909ed0fb945208a40e25ca8cfee12a1855637b9c\"\n",
    "\n",
    "\n",
    "messages = [{\"content\": \"You are a helpful assistant\", \"role\": \"system\"}, { \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    "\n",
    "# NOTE: adding \"together_ai/\" in front of the model name in https://docs.together.ai/docs/inference-models before calling.\n",
    "response = completion(\n",
    "    model=\"together_ai/meta-llama/Llama-3-8b-chat-hf\", \n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = \"together_ai/meta-llama/Llama-3-8b-chat-hf\"\n",
    "system_prompt = \"\"\n",
    "user_prompt = \"Q: 1 + 1 = \"\n",
    "\n",
    "# print(togetherai(model, system_prompt, user_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## framework\n",
    "- generalize all the methods name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaofeng/Documents/GitHub/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's help Janet with her duck egg sales!\n",
      "\n",
      "Janet's ducks lay 16 eggs per day. She eats 3 eggs for breakfast, and bakes muffins with 4 eggs, so she uses a total of 3 + 4 = 7 eggs. That leaves 16 - 7 = 9 eggs remaining.\n",
      "\n",
      "Janet sells these 9 eggs at the farmers' market for $2 per egg. To find out how much she makes, we multiply the number of eggs by the price per egg:\n",
      "\n",
      "9 eggs x $2 per egg = $18\n",
      "\n",
      "So, Janet makes $18 every day at the farmers' market.\n"
     ]
    }
   ],
   "source": [
    "from reasoners.benchmark import gsm8k, aqua, blocksworld, bw_utils, prontoqa\n",
    "import json\n",
    "\n",
    "\n",
    "def togetherai(model, system_prompt, user_prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}]\n",
    "    response = completion(\n",
    "    model=model, \n",
    "    messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "class SideReasoner:\n",
    "    def __init__(self,\n",
    "                 task,\n",
    "                 method):\n",
    "        self.task = task\n",
    "        self.method = method\n",
    "        self.evaluator_mapper = {\"gsm8k\": gsm8k.GSM8KEvaluator,\n",
    "                                  \"aqua\": aqua.AQuAEvaluator, \n",
    "                                  \"blocksworld\": blocksworld.BWEvaluator, \n",
    "                                  \"prontoqa\": prontoqa}\n",
    "\n",
    "    def get_prompt(self, idx = 0, num_shot = 4):\n",
    "        with open(f'examples/CoT/{self.task}/prompts/{self.method}.json') as f:\n",
    "            prompt = json.load(f)\n",
    "        task = self.evaluator_mapper[self.task]\n",
    "        evaluator = task(output_extractor=None, answer_extractor=None, sample_prompt_type=self.method, init_prompt=prompt)\n",
    "        prompt = evaluator.sample_prompt(num_shot=num_shot)[self.method]\n",
    "        question = evaluator.full_dataset[idx]['question']\n",
    "        answer = evaluator.full_dataset[idx]['answer']\n",
    "\n",
    "        return prompt.format(QUESTION = question), answer\n",
    "\n",
    "    def inference(self, model, user_prompt, system_prompt = \"\"):\n",
    "        return togetherai(model, system_prompt, user_prompt)\n",
    "\n",
    "\n",
    "\n",
    "model = \"together_ai/meta-llama/Llama-3-8b-chat-hf\"\n",
    "system_prompt = \"you are a helpful assistant.\"\n",
    "reasoner = SideReasoner(task=\"gsm8k\", method=\"cot\")\n",
    "prompt, answer = reasoner.get_prompt()\n",
    "response = reasoner.inference(model=model, user_prompt=prompt, system_prompt=system_prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",\n",
       " 'answer': 'Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\\n#### 18'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os, pickle\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import random\n",
    "import copy\n",
    "\n",
    "class GSM8K:\n",
    "    def __init__(self, split = 'test'):\n",
    "        self.input_processor = lambda x: x[\"question\"]\n",
    "        self.full_dataset = datasets.load_dataset('gsm8k', 'main', split=split)\n",
    "        self._dataset_name = 'gsm8k'\n",
    "\n",
    "    def __str__(self):\n",
    "        return self._dataset_name\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return self.full_dataset\n",
    "    \n",
    "tmp = GSM8K()\n",
    "dataset = tmp.get_dataset()\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vanilla:\n",
    "    def __init__(self, dataset, shot):\n",
    "        self.dataset = dataset\n",
    "        self.shot = shot\n",
    "\n",
    "    def get_prompt(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\",\n",
       " 'answer': 'Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\\nShe makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\\n#### 18'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Task:\n",
    "    def __init__(self, model, algorithm, dataset):\n",
    "        self.model = model\n",
    "        self.algorithm = algorithm\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def inference(shots = 3):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def get_model_api(model):\n",
    "        return model\n",
    "\n",
    "    def get_model_local():\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "class Algorithm:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def vanilla():\n",
    "        return \"\"\n",
    "\n",
    "    def chain_of_thought():\n",
    "        return \"\"\n",
    "\n",
    "    def chain_of_thought_zero_shot():\n",
    "        return \"let's think step by step...\"\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 metrics=None):\n",
    "        self.dataset = dataset\n",
    "        self.metrics = metrics\n",
    "        self.dataset_mapper = {\"gsm8k\": GSM8K}\n",
    "\n",
    "    def get_dataset(self):\n",
    "        data_class = self.dataset_mapper[self.dataset]()\n",
    "        return data_class.get_dataset()\n",
    "\n",
    "\n",
    "    # def get_example(self, cnt = 3):      \n",
    "    #     pass\n",
    "\n",
    "\n",
    "dataset = Dataset(dataset=\"gsm8k\")\n",
    "tmp = dataset.get_dataset()\n",
    "tmp[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
